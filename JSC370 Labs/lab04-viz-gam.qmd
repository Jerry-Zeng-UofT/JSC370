---
title: "Lab 04 - Data Visualization and GAMs"
format:
  html:
    embed-resources: true
jupyter: python3
---

```{python}
#| label: setup
#| message: false
#| warning: false

#%pip install pygam
#%pip install folium
import pandas as pd
import numpy as np
from plotnine import *
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
from pygam import LinearGAM, s
import statsmodels.api as sm
from folium.plugins import MarkerCluster
```

# Learning Goals

- Read in and prepare the meteorological dataset
- Use `pd.merge()` to join two datasets
- Deal with missings and impute data
- Create several graphs with different `geoms` in `plotnine`
- Create a facet graph
- Conduct customizations of the graphs
- Fit smooth regression models using `pygam` and compare to a linear regression model

# Lab Description

We will work with the meteorological data from last week's lab.

**The objective of the lab is to examine the association between weather variables in the US, practice data visualization, and fit smooth regression models.**


### 1. Read in the data

First download and then read in with pandas:

```{python}
url = "https://raw.githubusercontent.com/JSC370/JSC370-2026/main/data/met_all_2025.gz"
met = pd.read_csv(url, compression="gzip")
```

### 2. Prepare the data: some wrangling

- From last week: remove temperatures less than -20C and change 999.9 to NaN.
- Generate a date variable using `pd.to_datetime()`.
- Using date filtering, keep the observations of the first week of July 2025.
- Compute the mean by station of the variables `temp`, `rh`, `wind_sp`, `vis_dist`, `dew_point`, `lat`, `lon`, and `elev`.
- Create a region variable for NW, SW, NE, SE based on lon = -98.00 and lat = 39.71 degrees.
- Create a categorical variable for elevation (low: < 252m, high: >= 252m)

```{python}
# Replace 999.9 with NaN and filter temps > -20
met.loc[met['temp'] == 999.9, 'temp'] = np.nan
met = met[met['temp'] > -20].copy()

# Create date variable
met['date'] = pd.to_datetime(
    met[['year', 'month', 'day', 'hour']])

# Create region variable using np.select
met['region'] = (
    np.select(
        [
            (met['lon'] < -98) & (met['lat'] >= 39.71),
            (met['lon'] >= -98) & (met['lat'] >= 39.71),
            (met['lon'] < -98) & (met['lat'] < 39.71),
        ],
        ['NW', 'NE', 'SW'],
        default='SE'
    )
)

# Create elevation category
met['elev_high_low'] = np.select(
    [met['elev'] >= 252],
    ['high'],
    default='low'
)

display(met.head())
```



### 3. Use `geom_violin` to examine `dew_point` for low and high elevations by region

Use `geom_violin` and subset the data to the first two weeks in July.

- Subset to the first two weeks in July
- Use facets
- Summarize below

```{python}
# Subset to first two weeks of July
met_july = met[(met['date'] >= '2025-07-01') & (met['date'] < '2025-07-15')].copy()

# Create violin plot with facets
(ggplot(met_july,
        aes(x='elev_high_low', y='dew_point', fill='elev_high_low')) +
  geom_violin() +
  facet_wrap('~region') +
  labs(x='Evelation Category', y='Dew point Temperature',
       title='Dew point by elevation and Region') +
  theme_minimal())

```

Summary:
- For NE and SE, the elevation has low effect on general. The dew point is dense around 20 for these two region. For NW and SW, evelation has higher impact. high elevation has more spread dew point, while low elevation has denser dew point. Apart from the effect of elevation, the region has high influence on the dew point, with SW and NW have lower dew point than NE and SE in general. 

### 4. Use `geom_bar` to create barplots of the proportion of weather stations by elevation category colored by region

- Use the subset data from \#3, the first two weeks of July
- Create nice labels on axes and add a title
- Try a second plot with counts and `dodge` positioning
- Summarize below

```{python}
# Proportion barplot (position='fill')
(ggplot(met_july,
        aes(x='elev_high_low', fill='region')) +
  geom_bar(position='fill') +
  scale_fill_brewer(type='qual', palette='Set2') +
  labs(x='Elevation Category', y='Proportion of Stations',
       title='Proportion of Weather Station by Evaluation and Region') +
  theme_minimal())
```

```{python}
# Count barplot with dodge positioning
(ggplot(met_july,
        aes(x='elev_high_low', fill='region')) +
  geom_bar(position='dodge') +
  scale_fill_brewer(type='qual', palette='Set2') +
  labs(x='Elevation Category', y='Counts of Stations',
       title='Count of Weather Station by Evaluation and Region') +
  theme_minimal())
```

Summary:
- In the first proportion graph, we see NE takes the largest proportion, followed by SW. NE and SE take about the same proportion. Overall stations are relativly even. That said, with low elevation, SE takes more than half of the proportion, followed by NE, whereas SW and NW are almost negligible.
- In the count graph (dodge), the information is about the same, but we can compare the total across the high and low region, which we cannot with only the proportion. 

### 5. Use `stat_summary` to examine mean dew point by region with standard deviation error bars

- Use `stat_summary` with appropriate functions for mean and standard deviation
- Add error bars using another layer of `stat_summary` with `geom = "errorbar"`
- Use `coord_flip`
- Add labels and a title
- Summarize below

```{python}
# Use stat_summary with fun_y, fun_ymin, fun_ymax
# Hint: fun_ymin=lambda x: np.mean(x) - np.std(x)

(ggplot(met_july, aes(x='region', y='dew_point')) +
  stat_summary(fun_y=np.mean,
               fun_ymin=lambda x: np.mean(x) - np.std(x),
               fun_ymax=lambda x: np.mean(x) + np.std(x),
               geom='errorbar') +
  coord_flip() +
  labs(x='Region', y='Dew Point Temperature',
       title='Mean and sd dew point temperature by geographic region') +
  theme_minimal())
```

Summary:
- Similar as what we saw in the faceted volin plot before, NE and SE have generally higher dew point with lower spread (variance), whereas SW and NW have lower dew point on avergae but vary lot. 

### 6. Smooth Regression with GAMs

Let's practice running regression models with smooth functions on X. We use the `statsmodels` OLS for linear models and `pygam` package and `LinearGAM` function to do this.

- Use the subsetted data. First remove NaN before fitting
- Fit both a linear model with `sm.OLS` and a spline model (use `LinearGAM()` with `s()` for a smooth term on wind_sp and temp).
- For the spline model try `n_splines` = 20
- Summarize and plot the results from the models.

```{python}
# Data prep
# Remove NaN values before fitting
met_clean = met_july.dropna(subset=['wind_sp', 'temp', 'dew_point'])

X = met_clean[['wind_sp', 'temp']].values
y = met_clean['dew_point'].values
```

- Now fit linear model with sm.OLS

```{python}
# Don't forget to add a constant
X_const = sm.add_constant(X)

linear_mod = sm.OLS(y, X_const).fit()
print("Linear Model:")
print(linear_mod.summary())
```

Summary:

- Report adjusted R2
- Are the beta coefficients for wind speed and temperature significant?

- the adjusted R-square is 0.115 about 11.5% of the variation is explained by the model
- both ceofficients have 0.000 p-value, under almost any common threshold, say 0.05, they are considered significant.

```{python}
# GAM spline model
# Use LinearGAM with s() for smooth terms
# s(0) refers to first column, s(1) to second column

gam_mod = LinearGAM(
    s(0, n_splines=20) +
    s(1, n_splines=20)).fit(X, y)
print("\nSmooth Spline Model:")
print(gam_mod.summary())
```

Summary:

- Report pseudo R2, how does it compare to the linear model R2?
- What are the EDoF for wind speed and temp?
- Are the smooths for wind speed and temperature significant?

- The Pseduo R-square is 0.2868, its between 0.2 and 0.4 which indicates a good model fit. 
- The EDof for wind speed and temp are 13.5 and 16.9 repsectivly
- The p-value for both variables are very low (1.11e_6, almost negligible), so they are considered significant. 

```{python}
#| fig-align: center
# Plot partial dependence curves for each predictor

# define the figure size
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# define the variables and colors
spec = [
    (0, 0, "Wind Speed",  "blue", "Effect of Wind Speed"),
    (1, 1, "Temperature", "red",  "Effect of Temperature"),
]

# loop over smooth variables
for ax, (term, xcol, xlabel, color, title) in zip(axes, spec):
    XX = gam_mod.generate_X_grid(term=term)
    x = XX[:, xcol]
    pd_effect = gam_mod.partial_dependence(term=term, X=XX)
    _, ci = gam_mod.partial_dependence(term=term, X=XX, width=0.95)

    ax.plot(x, pd_effect, color=color, lw=2)
    ax.plot(x, ci, color=color, ls="--", lw=1)
    ax.set(xlabel=xlabel, ylabel="Partial Effect on Dew Point", title=title)

plt.tight_layout()
plt.show()
```

Summary:

- Visual inspection of the fitted curves
- Does the smooth term capture meaningful non-linearity?

- Visual inspection: both curve are non-linear, the effect of wind speed is more spread out for high wind speed, while that of temperature is more tighten. 
- The smooth term does capture meaningful non-linearity according to the Pseduo R-square. Intuitively, the shape of both curve are significantly non-linear, so the non-linearity is captured by the model. 